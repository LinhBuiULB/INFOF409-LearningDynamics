{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical simulations of stochastic evolutionary Dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these simulations we will implement the Moran process on a mixed population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys, getopt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Multi-processing\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Magic function to make matplotlib inline; other style specs must come AFTER\n",
    "%matplotlib inline\n",
    "\n",
    "# This enables SVG graphics inline.  There is a bug, so uncomment if it works.\n",
    "# %config InlineBackend.figure_formats = {'svg',}\n",
    "\n",
    "# This enables high resolution PNGs. SVG is preferred, but has problems\n",
    "# rendering vertical and horizontal lines\n",
    "%config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook contains the code for producing the finite population dynamics of the iterated prisoners dilemma. As a first step we define the parameters of the simulation as global values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Z=50                    # Population size\n",
    "T=5.                    # Temptation to defect\n",
    "R=3.                    # Reward for mutual cooperation\n",
    "P=1.                    # Punishment for mutual defection\n",
    "S=0.                    # Suckers payoff for unilateral cooperation\n",
    "q=4                     # Number of strategies\n",
    "rounds=10               # Number of rounds\n",
    "drift=1.0/Z             # Random drift between strategies\n",
    "beta=0.01               # Intensity of selection\n",
    "runs = 100              # Number of independent repetitions of each simulation\n",
    "generations = 10e3      # Number of generations\n",
    "\n",
    "# Let numpy initialize the seed from the machine random entropy source\n",
    "np.random.seed(None)\n",
    "# Retrieve the initial state to be able to reproduce the results\n",
    "st0 = np.random.get_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# payoff matrix\n",
    "payoffs = np.array([\n",
    "    [P, T],\n",
    "    [S, R]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Strategy labels\n",
    "strats = ['C','D', 'TFT', 'RANDOM'] # 1, 2, 3, 4\n",
    "actions = {'D': 0, 'C': 1}\n",
    "action_vector = [actions['D'], actions['C']]\n",
    "\n",
    "\n",
    "def all_C(prev_action):\n",
    "    return actions['C']\n",
    "\n",
    "def all_D(prev_action):\n",
    "    return actions['D']\n",
    "\n",
    "def tft(prev_action):\n",
    "    return actions['C'] if prev_action == actions['C'] else actions['D']\n",
    "\n",
    "def random_player(prev_action):\n",
    "    return np.random.choice(action_vector, replace=True, size=1)\n",
    "\n",
    "get_action = {\n",
    "    'C': all_C,\n",
    "    'D': all_D,\n",
    "    'TFT': tft,\n",
    "    'RANDOM': random_player\n",
    "}\n",
    "    \n",
    "\n",
    "def player_factory(pop_size, freq=[0.25, 0.25, 0.25, 0.25]):\n",
    "    \"\"\"\n",
    "    Generates a numpy array of strings of pop_size that define the distribution \n",
    "    of the population.\n",
    "    freq defines the frequencies of each of the strategies in the initial population.\n",
    "    \"\"\"\n",
    "    return np.random.choice(strats, replace=True, p=freq, size=pop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fermifunc(b,first, second):\n",
    "    '''\n",
    "    The fermi function determines the probability that the first type imitates the second\n",
    "    '''\n",
    "    return 1./(1. + np.exp(-b*(first-second)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the 2-IPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "game_actions = np.zeros(shape=(rounds, 2), dtype=np.int32)\n",
    "game_payoffs = np.zeros(shape=(rounds, 2), dtype=np.int32)\n",
    "def iterated_prisoners_dilemma(player1, player2, rounds):\n",
    "    \"\"\"\n",
    "    Plays a 2-player iterated prisoner's dilemma and returns the total payoff of each\n",
    "    player.\n",
    "    \"\"\"\n",
    "    # initialize actions\n",
    "    game_actions[-1, :] = [1, 1]\n",
    "    for r in range(rounds):\n",
    "        game_actions[r, 0] = get_action[player1](game_actions[r-1, 1])\n",
    "        game_actions[r, 1] = get_action[player2](game_actions[r-1, 0])\n",
    "        game_payoffs[r, :] = payoffs[game_actions[r, 0], game_actions[r, 1]], \\\n",
    "                                payoffs[game_actions[r, 1], game_actions[r, 0]]\n",
    "    return game_payoffs.sum(axis=0)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the moran process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what you have to implement!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "population_indexes = np.arange(0, Z, dtype=np.int64)\n",
    "def moran_process(beta, population):\n",
    "    \"\"\"\n",
    "    This function implements a birth-death process over the population. \n",
    "    At time t, two players are randomly selected from the population\n",
    "    \"\"\"\n",
    "    strategy1 = player_factory(population)\n",
    "    strategy2 = player_factory(population)\n",
    "    \n",
    "    fitness1 = iterated_prisoners_dilemma(strategy1, strategy2, rounds)\n",
    "    fitness2 = iterated_prisoners_dilemma(strategy2, strategy1, rounds)\n",
    "    \n",
    "    if random.rand(0,1) < fermiFunction(beta,fitness1,fitness2):\n",
    "        strategy1 = strategy2\n",
    "    else:\n",
    "        strategy2 = strategy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_strategy_freq(population):\n",
    "    \"\"\"\n",
    "    Calculates the frequency of each strategy within a population at a given generation\n",
    "    \"\"\"\n",
    "    freq_C = population[population == \"C\"].shape[0] / float(Z)\n",
    "    freq_D = population[population == \"D\"].shape[0] / float(Z)\n",
    "    freq_TFT = population[population == \"TFT\"].shape[0] / float(Z)\n",
    "    freq_RANDOM = population[population == \"RANDOM\"].shape[0] / float(Z)\n",
    "    \n",
    "    return np.array([population[population == strat].size for strat in strats]) / Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we implement the simulation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evolve(beta, generations, population_size):\n",
    "    \"\"\"\n",
    "    Specifies the evolutionary loop\n",
    "    \"\"\"\n",
    "    freq_vector = np.zeros(shape=(int(generations), q), dtype=np.float64)\n",
    "    population = player_factory(population_size, [0.25, 0.25, 0.25, 0.25])\n",
    "    for gen in range(int(generations)):\n",
    "        # Playe 2IPD and update population\n",
    "        moran_process(beta, population)\n",
    "        # Calculate the intermediate frequencies of each strategy\n",
    "        freq_vector[gen, :] = calculate_strategy_freq(population)\n",
    "    return freq_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate initial population\n",
    "betas=[0.00001,0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0]\n",
    "shape = (len(betas), int(runs), int(generations), q)\n",
    "freq_vector = np.zeros((len(betas), int(runs), int(generations), q), dtype=np.float64)\n",
    "results = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Specify here as many processes as your processor allows!\n",
    "pool = Pool(processes=8)\n",
    "\n",
    "for i, beta in enumerate(betas):\n",
    "    for j in range(int(runs)):\n",
    "        results.append(pool.apply_async(evolve, (beta, generations, Z,)))\n",
    "\n",
    "ct = 0\n",
    "for i, beta in enumerate(betas):\n",
    "    for j in range(int(runs)):        \n",
    "        freq_vector[i, j, :, :] = results[ct].get()\n",
    "        ct +=1\n",
    "\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "print(\"The simulation took --- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot stationary distribution in function of beta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 7), dpi=150)\n",
    "threshold = 100\n",
    "lines=plt.plot(betas,np.mean(np.mean(freq_vector[:, :, -threshold:, 0], axis=2), axis=1),'bo-',\n",
    "               betas,np.mean(np.mean(freq_vector[:, :, -threshold:, 1], axis=2), axis=1),'rv-', \n",
    "               betas,np.mean(np.mean(freq_vector[:, :, -threshold:, 2], axis=2), axis=1),'gx-',\n",
    "               betas,np.mean(np.mean(freq_vector[:, :, -threshold:, 3], axis=2), axis=1),'y+-')\n",
    "plt.rc(\"font\", size=14)\n",
    "plt.xscale('log')\n",
    "plt.setp(lines, linewidth=2.0)\n",
    "plt.ylabel('Stationary distribution',size=16)\n",
    "plt.xlabel('selection strength'+r'($\\beta$)',size=16)\n",
    "plt.ylim(-0.05,1.05)\n",
    "plt.legend(strats)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
